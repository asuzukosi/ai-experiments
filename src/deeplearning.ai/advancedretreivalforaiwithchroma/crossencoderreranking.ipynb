{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross encoder reranking \n",
    "Cross encoder reranking is a retreival optimization technique that is provided by chroma. In this section we will be diving into the technique in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "from chromadb.api.client import Client\n",
    "from pypdf import PdfReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = PdfReader(\"MIV2 - LLM paper.pdf\")\n",
    "docs = [page.extract_text().strip() for page in doc.pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\", \" \", \".\", \"\\n\", \"\\n\\n\"], \n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = recursive_splitter.split_text(\"\\n\\n\".join(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kosisochukwuasuzu/Developer/ai-startups/test-demos/pdfchat/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/kosisochukwuasuzu/Developer/ai-startups/test-demos/pdfchat/venv/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "sentence_splitter = SentenceTransformersTokenTextSplitter(\n",
    "    chunk_overlap=0, \n",
    "    tokens_per_chunk=256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text = []\n",
    "for t in text:\n",
    "    split_text += sentence_splitter.split_text(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = SentenceTransformerEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "collection = client.create_collection(name=\"new_test\", embedding_function=embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [ str(i) for i in range(len(split_text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "collection.add(ids=ids, documents=split_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_docs = collection.query(query_texts=\"what is the general idea of the research paper\", n_results=5)[\"documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pp. 10608 - 10615 ). ieee. [ 31 ] bergerman, m., maeta, s. m., zhang, j., freitas, g. m., hamner, b., singh, s. and kantor,',\n",
       " 'n behavior. in proceedings of the 36th annual acm symposium on user interface software and technology ( pp. 1 - 22 ). appendix a section title of first appendix an appendix contains supplementary information that is not an essential part of the text itself but which may be helpful in providing a more comprehensive understanding of the research problem or it is information that is too cumbersome to be included in the body of the paper. 17',\n",
       " 'socratic models : composing zero - shot multimodal reasoning with language. arxiv preprint arxiv : 2204. 00598. [ 45 ] zhao, z., lee, w. s. and hsu, d., 2023. large language models as commonsense knowledge for large - scale task planning. arxiv preprint arxiv : 2305. 14078. [ 46 ] yao, s., yu, d., zhao, j., shafran, i., griffiths, t. l., cao, y. and narasimhan, k., 2023. tree of thoughts : deliberate probl',\n",
       " 'interface software and technology ( pp. 1 - 22 ). appendix a section title of first appendix an appendix contains supplementary informat',\n",
       " 'ch algorithm, was employed in this exploration. this involved integrating the world model into the policy for a search algorithm like mcts. concurrently, llms with tree - of - thought ( llm - tot ) approach adopted a tree - based strategy, enabling llms to engage in deliberate decision - making by assessing various reasoning paths and self - evaluating choices to determine the subsequent course of action [ 46 ]. the results of these studies highlight the effectiveness of search - based plan generation over policies induced by llms. nevertheless, given the straightforward nature of the tasks in these experiments, the decision is made to refrain from employing the search - based approach. instead, reliance is placed on the llm - induced policies in their original form. recent research endeavors have prominently concentrated on formulating task plans grounded in high - level natural language descriptions, thereby endowing robots with the capability to execute intricate tasks with minimal human intervention [ 34 ]']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the general idea of the research paper\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "-10.947703\n",
      "-8.723831\n",
      "-11.054613\n",
      "-11.399334\n",
      "-9.394058\n"
     ]
    }
   ],
   "source": [
    "pairs = [[query, doc] for doc in relevant_docs]\n",
    "scores = cross_encoder.predict(pairs)\n",
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ordering:\n",
      "2\n",
      "5\n",
      "1\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(\"New Ordering:\")\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o+1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
