{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory\n",
    "This section covers the use of memory modules in langchain and how we can use prebuilt chains for accessing memory to build a simple conversational AI.\n",
    "\n",
    "Outline for various memeory types\n",
    "* ConversationalBufferMemory\n",
    "* ConversationalBufferWindowMemory\n",
    "* ConversationalTokenBufferMemory\n",
    "* ConversationalSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'mistralai/Mistral-7B-Instruct-v0.2',\n",
       " 'stream': False,\n",
       " 'n': 1,\n",
       " 'temperature': 0.0}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "mistral_7b = ChatOpenAI(temperature=0.0, model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
    "mistral_7b._default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate conversation memory \n",
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_chain = ConversationChain(\n",
    "    llm=mistral_7b,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi my name is Kosi\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Kosi, nice to meet you. I'm an AI language model. How can I assist you today?\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_chain.predict(input=\"Hi my name is Kosi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Kosi\n",
      "AI: Hello Kosi, nice to meet you. I'm an AI language model. How can I assist you today?\n",
      "Human: What is 1 + 1?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to the mathematical expression \"1 + 1\" is \"2\". This is a basic arithmetic operation where \"1\" is added to \"1\", resulting in a sum of \"2\".'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_chain.predict(input=\"What is 1 + 1?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Kosi\n",
      "AI: Hello Kosi, nice to meet you. I'm an AI language model. How can I assist you today?\n",
      "Human: What is 1 + 1?\n",
      "AI: The answer to the mathematical expression \"1 + 1\" is \"2\". This is a basic arithmetic operation where \"1\" is added to \"1\", resulting in a sum of \"2\".\n",
      "Human: What is my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Kosi, as you introduced yourself at the beginning of our conversation.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_chain.predict(input=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi my name is Kosi\n",
      "AI:  Hello Kosi! My name is LLaMA, I'm a large language model trained by a team of researcher at Meta AI. It's nice to meet you! What brings you here today?\n",
      "Human: What is 1 + 1?\n",
      "AI:  Sure! The answer to 1 + 1 is 2. Would you like to know anything else?\n",
      "Human: What is my name?\n",
      "AI:  AI: I don't know your name. I'm just an AI, I don't have access to personal information or the ability to perceive the physical world. I can only provide information based on my training data, and I don't have any information about you personally. Is there anything else I can help you with?\n",
      "Human: I mentioned it earlier in the conversation\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Ah, my apologies! You did mention your name earlier in the conversation. Your name is Kosi. Is there anything else you would like to know or discuss?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_chain.predict(input=\"I mentioned it earlier in the conversation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(memory.buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': 'Human: Hi my name is Kosi\\n'\n",
      "            \"AI: Hello Kosi, nice to meet you. I'm an AI language model. How \"\n",
      "            'can I assist you today?\\n'\n",
      "            'Human: What is 1 + 1?\\n'\n",
      "            'AI: The answer to the mathematical expression \"1 + 1\" is \"2\". '\n",
      "            'This is a basic arithmetic operation where \"1\" is added to \"1\", '\n",
      "            'resulting in a sum of \"2\".\\n'\n",
      "            'Human: What is my name?\\n'\n",
      "            'AI: Kosi, as you introduced yourself at the beginning of our '\n",
      "            'conversation.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"}) # we can start hte memory with some predifined context, but why is it called input and output rather than human and AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Hi\\nAI: What's up\"}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({}) # extract variables from the conversational buffer memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Not much, just hanging\"}, \n",
    "                    {\"output\": \"Cool\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Hi\n",
      "AI: What's up\n",
      "Human: Not much, just hanging\n",
      "AI: Cool\n"
     ]
    }
   ],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use ConversationBufferWindowMemory to optimize the context that is being sent to the LLM \n",
    "This would help reduce the conmpounding cost of the LLM session as the context expands with the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=4) # stores only the last k messages in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_window_chain = ConversationChain(\n",
    "    llm=mistral_7b,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, my name is Kosi and I am 23 years old\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello Kosi, nice to meet you. I'm an AI and don't have the ability to age or have a name. I'm here to help answer any questions you might have to the best of my ability. You mentioned you're 23 years old. Is there a specific question related to that age or something else you'd like to know?\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_chain.predict(input=\"Hello, my name is Kosi and I am 23 years old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Kosi and I am 23 years old\n",
      "AI: Hello Kosi, nice to meet you. I'm an AI and don't have the ability to age or have a name. I'm here to help answer any questions you might have to the best of my ability. You mentioned you're 23 years old. Is there a specific question related to that age or something else you'd like to know?\n",
      "Human: What is the captial of Nigeria?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The capital city of Nigeria is Abuja. It became the capital in 1991, replacing Lagos. Abuja is located in the center of the country and is known for its modern architecture and urban planning. It has a population of over 2 million people. Is there anything else you'd like to know?\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_chain.predict(input=\"What is the captial of Nigeria?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Kosi and I am 23 years old\n",
      "AI: Hello Kosi, nice to meet you. I'm an AI and don't have the ability to age or have a name. I'm here to help answer any questions you might have to the best of my ability. You mentioned you're 23 years old. Is there a specific question related to that age or something else you'd like to know?\n",
      "Human: What is the captial of Nigeria?\n",
      "AI: The capital city of Nigeria is Abuja. It became the capital in 1991, replacing Lagos. Abuja is located in the center of the country and is known for its modern architecture and urban planning. It has a population of over 2 million people. Is there anything else you'd like to know?\n",
      "Human: how old am i?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm sorry for any confusion, Kosi. You mentioned that you are 23 years old at the beginning of our conversation. Is there a specific question related to that age or something else you'd like to know?\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_chain.predict(input=\"how old am i?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Kosi and I am 23 years old\n",
      "AI: Hello Kosi, nice to meet you. I'm an AI and don't have the ability to age or have a name. I'm here to help answer any questions you might have to the best of my ability. You mentioned you're 23 years old. Is there a specific question related to that age or something else you'd like to know?\n",
      "Human: What is the captial of Nigeria?\n",
      "AI: The capital city of Nigeria is Abuja. It became the capital in 1991, replacing Lagos. Abuja is located in the center of the country and is known for its modern architecture and urban planning. It has a population of over 2 million people. Is there anything else you'd like to know?\n",
      "Human: how old am i?\n",
      "AI: I'm sorry for any confusion, Kosi. You mentioned that you are 23 years old at the beginning of our conversation. Is there a specific question related to that age or something else you'd like to know?\n",
      "Human: what is the most popular algorithm in computer science\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The most popular algorithm in computer science can vary depending on the specific area of application. However, some of the most commonly used algorithms include:\\n\\n1. QuickSort for sorting data\\n2. Dijkstra's Algorithm for finding the shortest path between nodes in a graph\\n3. Floyd-Warshall Algorithm for finding the shortest paths between all pairs of nodes in a weighted graph\\n4. Depth-First Search (DFS) and Breadth-First Search (BFS) for traversing graphs\\n5. Hashing algorithms like HashTable and HashMap for efficient data storage and retrieval\\n6. Gradient Descent for optimization problems in machine learning\\n\\nIs there a specific algorithm you have in mind that you'd like to know more about?\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_chain.predict(input=\"what is the most popular algorithm in computer science\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, my name is Kosi and I am 23 years old\n",
      "AI: Hello Kosi, nice to meet you. I'm an AI and don't have the ability to age or have a name. I'm here to help answer any questions you might have to the best of my ability. You mentioned you're 23 years old. Is there a specific question related to that age or something else you'd like to know?\n",
      "Human: What is the captial of Nigeria?\n",
      "AI: The capital city of Nigeria is Abuja. It became the capital in 1991, replacing Lagos. Abuja is located in the center of the country and is known for its modern architecture and urban planning. It has a population of over 2 million people. Is there anything else you'd like to know?\n",
      "Human: how old am i?\n",
      "AI: I'm sorry for any confusion, Kosi. You mentioned that you are 23 years old at the beginning of our conversation. Is there a specific question related to that age or something else you'd like to know?\n",
      "Human: what is the most popular algorithm in computer science\n",
      "AI: The most popular algorithm in computer science can vary depending on the specific area of application. However, some of the most commonly used algorithms include:\n",
      "\n",
      "1. QuickSort for sorting data\n",
      "2. Dijkstra's Algorithm for finding the shortest path between nodes in a graph\n",
      "3. Floyd-Warshall Algorithm for finding the shortest paths between all pairs of nodes in a weighted graph\n",
      "4. Depth-First Search (DFS) and Breadth-First Search (BFS) for traversing graphs\n",
      "5. Hashing algorithms like HashTable and HashMap for efficient data storage and retrieval\n",
      "6. Gradient Descent for optimization problems in machine learning\n",
      "\n",
      "Is there a specific algorithm you have in mind that you'd like to know more about?\n",
      "Human: what is my name\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Kosi, you mentioned that your name is Kosi at the beginning of our conversation.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_chain.predict(input=\"what is my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationBufferWindowMemory(chat_memory=ChatMessageHistory(messages=[HumanMessage(content='Hello, my name is Kosi and I am 23 years old'), AIMessage(content=\"Hello Kosi, nice to meet you. I'm an AI and don't have the ability to age or have a name. I'm here to help answer any questions you might have to the best of my ability. You mentioned you're 23 years old. Is there a specific question related to that age or something else you'd like to know?\"), HumanMessage(content='What is the captial of Nigeria?'), AIMessage(content=\"The capital city of Nigeria is Abuja. It became the capital in 1991, replacing Lagos. Abuja is located in the center of the country and is known for its modern architecture and urban planning. It has a population of over 2 million people. Is there anything else you'd like to know?\"), HumanMessage(content='how old am i?'), AIMessage(content=\"I'm sorry for any confusion, Kosi. You mentioned that you are 23 years old at the beginning of our conversation. Is there a specific question related to that age or something else you'd like to know?\"), HumanMessage(content='what is the most popular algorithm in computer science'), AIMessage(content=\"The most popular algorithm in computer science can vary depending on the specific area of application. However, some of the most commonly used algorithms include:\\n\\n1. QuickSort for sorting data\\n2. Dijkstra's Algorithm for finding the shortest path between nodes in a graph\\n3. Floyd-Warshall Algorithm for finding the shortest paths between all pairs of nodes in a weighted graph\\n4. Depth-First Search (DFS) and Breadth-First Search (BFS) for traversing graphs\\n5. Hashing algorithms like HashTable and HashMap for efficient data storage and retrieval\\n6. Gradient Descent for optimization problems in machine learning\\n\\nIs there a specific algorithm you have in mind that you'd like to know more about?\"), HumanMessage(content='what is my name'), AIMessage(content='Kosi, you mentioned that your name is Kosi at the beginning of our conversation.')]), k=4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "Human: What is the captial of Nigeria?\n",
      "AI: The capital city of Nigeria is Abuja. It became the capital in 1991, replacing Lagos. Abuja is located in the center of the country and is known for its modern architecture and urban planning. It has a population of over 2 million people. Is there anything else you'd like to know?\n",
      "Human: how old am i?\n",
      "AI: I'm sorry for any confusion, Kosi. You mentioned that you are 23 years old at the beginning of our conversation. Is there a specific question related to that age or something else you'd like to know?\n",
      "Human: what is the most popular algorithm in computer science\n",
      "AI: The most popular algorithm in computer science can vary depending on the specific area of application. However, some of the most commonly used algorithms include:\n",
      "\n",
      "1. QuickSort for sorting data\n",
      "2. Dijkstra's Algorithm for finding the shortest path between nodes in a graph\n",
      "3. Floyd-Warshall Algorithm for finding the shortest paths between all pairs of nodes in a weighted graph\n",
      "4. Depth-First Search (DFS) and Breadth-First Search (BFS) for traversing graphs\n",
      "5. Hashing algorithms like HashTable and HashMap for efficient data storage and retrieval\n",
      "6. Gradient Descent for optimization problems in machine learning\n",
      "\n",
      "Is there a specific algorithm you have in mind that you'd like to know more about?\n",
      "Human: what is my name\n",
      "AI: Kosi, you mentioned that your name is Kosi at the beginning of our conversation.\n",
      "Human: what is the captial of America?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I\\'m sorry for any confusion, but it seems there is a misunderstanding. The term \"America\" can refer to either the United States of America or the entire continent of North, Central, and South America. If you meant to ask about the capital city of the United States of America, it is Washington, D.C. If you meant to ask about the capital city of a specific country in South or Central America, please provide the name of that country.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_chain.predict(input=\"what is the captial of America?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "Human: how old am i?\n",
      "AI: I'm sorry for any confusion, Kosi. You mentioned that you are 23 years old at the beginning of our conversation. Is there a specific question related to that age or something else you'd like to know?\n",
      "Human: what is the most popular algorithm in computer science\n",
      "AI: The most popular algorithm in computer science can vary depending on the specific area of application. However, some of the most commonly used algorithms include:\n",
      "\n",
      "1. QuickSort for sorting data\n",
      "2. Dijkstra's Algorithm for finding the shortest path between nodes in a graph\n",
      "3. Floyd-Warshall Algorithm for finding the shortest paths between all pairs of nodes in a weighted graph\n",
      "4. Depth-First Search (DFS) and Breadth-First Search (BFS) for traversing graphs\n",
      "5. Hashing algorithms like HashTable and HashMap for efficient data storage and retrieval\n",
      "6. Gradient Descent for optimization problems in machine learning\n",
      "\n",
      "Is there a specific algorithm you have in mind that you'd like to know more about?\n",
      "Human: what is my name\n",
      "AI: Kosi, you mentioned that your name is Kosi at the beginning of our conversation.\n",
      "Human: what is the captial of America?\n",
      "AI: I'm sorry for any confusion, but it seems there is a misunderstanding. The term \"America\" can refer to either the United States of America or the entire continent of North, Central, and South America. If you meant to ask about the capital city of the United States of America, it is Washington, D.C. If you meant to ask about the capital city of a specific country in South or Central America, please provide the name of that country.\n",
      "Human: what is my name\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Kosi, you mentioned that your name is Kosi at the beginning of our conversation.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_window_chain.predict(input=\"what is my name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversational Token Buffer Memory\n",
    "\n",
    "Even though we can limit the number of messages that go into our context for the LLM, a single message can be very large and fill up the entire context window, we would want to measure the number the number of messages that should go into the context of the LLM based on number of tokens \n",
    "That is what the ConversationalTokenBufferMemory helps us to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_buffer_memory = ConversationTokenBufferMemory(max_token_limit=50, llm=mistral_7b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_buffer_memory.save_context({\"input\": \"AI is what?!\"},\n",
    "                    {\"output\": \"Amazing!\"})\n",
    "token_buffer_memory.save_context({\"input\": \"Backpropagation is what?\"},\n",
    "                    {\"output\": \"Beautiful!\"})\n",
    "token_buffer_memory.save_context({\"input\": \"Chatbots are what?\"}, \n",
    "                    {\"output\": \"Charming!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'AI: Amazing!\\nHuman: Backpropagation is what?\\nAI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_buffer_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_buffer_memory.save_context({\"input\": \"Oooouuuu whatcha ssaaayyyyyyy, would you bring your lovin my wayyyy\"}, \n",
    "                    {\"output\": \"Ooouuu whatcha building my friend\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Oooouuuu whatcha ssaaayyyyyyy, would you bring your lovin my wayyyy\\nAI: Ooouuu whatcha building my friend'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_buffer_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also use ConversationSummaryMemory\n",
    "This summarizes the conversation up to a point and usese the summerized version of the ocnversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a long string\n",
    "schedule = \"There is a meeting at 8am with your product team. \\\n",
    "You will need your powerpoint presentation prepared. \\\n",
    "9am-12pm have time to work on your LangChain \\\n",
    "project which will go quickly because Langchain is such a powerful tool. \\\n",
    "At Noon, lunch at the italian resturant with a customer who is driving \\\n",
    "from over an hour away to meet you to understand the latest in AI. \\\n",
    "Be sure to bring your laptop to show the latest LLM demo.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=mistral_7b, max_token_limit=100)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"What is on the schedule today?\"}, \n",
    "                    {\"output\": f\"{schedule}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_conversation_chain = ConversationChain(\n",
    "    llm=mistral_7b,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI and asks about the day's schedule. The AI responds by mentioning a 8am meeting with the product team where the human needs to prepare a powerpoint presentation. From 9am to 12pm, the human has time to work on the LangChain project, which the AI describes as a powerful tool. At noon, there is a lunch appointment with a customer who is coming from a long distance to discuss the latest advancements in AI. The human is advised to bring their laptop to demonstrate the LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Based on the latest advancements in AI, I would recommend demonstrating the language model's ability to understand and generate human-like text. You could also showcase its capability to answer complex questions, summarize long texts, and even generate creative content like poetry or stories. Additionally, you could demonstrate its integration with other applications or systems, if applicable.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_conversation_chain.predict(input=\"What would be a good demo to show?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. \n",
      "The AI is talkative and provides lots of specific details from its context. Check the current conversation section for context. \n",
      "If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "DO NOT TRY TO CONTINUE THE CONVERSATION ON YOUR OWN, ONLY PROVIDE THE A SINGLE AI RESPONSE.\n",
      "Return just the response.\n",
      "\n",
      "Current conversation:\n",
      "System: The human greets the AI and asks about the day's schedule. The AI responds by mentioning a 8am meeting with the product team where the human needs to prepare a powerpoint presentation. From 9am to 12pm, the human has time to work on the LangChain project, which the AI describes as a powerful tool. At noon, there is a lunch appointment with a customer who is coming from a long distance to discuss the latest advancements in AI. The human is advised to bring their laptop to demonstrate the LLM demo.\n",
      "Human: What would be a good demo to show?\n",
      "AI: Based on the latest advancements in AI, I would recommend demonstrating the language model's ability to understand and generate human-like text. You could also showcase its capability to answer complex questions, summarize long texts, and even generate creative content like poetry or stories. Additionally, you could demonstrate its integration with other applications or systems, if applicable.\n",
      "Human: how many hours do i have to work on my langchain project today?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You have a total of 3 hours to work on the LangChain project today, from 9am to 12pm.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_conversation_chain.predict(input=\"how many hours do i have to work on my langchain project today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'history': \"System: The human greets the AI and asks about the day's \"\n",
      "            'schedule. The AI informs the human of an 8am meeting with the '\n",
      "            'product team where they need to prepare a powerpoint '\n",
      "            'presentation. From 9am to 12pm, the human has time to work on the '\n",
      "            'LangChain project, which the AI describes as a powerful tool. At '\n",
      "            'noon, there is a lunch appointment with a customer coming from a '\n",
      "            'long distance. The human is advised to bring their laptop to '\n",
      "            \"demonstrate the language model's ability to understand and \"\n",
      "            'generate human-like text, answer complex questions, summarize '\n",
      "            'long texts, generate creative content, and integrate with other '\n",
      "            'applications or systems.\\n'\n",
      "            'Human: how many hours do i have to work on my langchain project '\n",
      "            'today?\\n'\n",
      "            'AI: You have a total of 3 hours to work on the LangChain project '\n",
      "            'today, from 9am to 12pm.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(memory.load_memory_variables({}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
