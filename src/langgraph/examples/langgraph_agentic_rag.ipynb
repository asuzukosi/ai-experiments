{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LangGraph Retrieval Agent\n",
    "\n",
    "Retrieval Agents are useful when we want to make decisions about whether to retrieve from an index. \n",
    "To implement a retrieval agent, we simply need to give an LLM access to a retreiver tool.\n",
    "We will be incoperating this into langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores.chroma import Chroma\n",
    "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    # \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    # \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "from typing import Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embeddings(texts, model=\"togethercomputer/m2-bert-80M-32k-retrieval\"):\n",
    "   texts = [text.replace(\"\\n\", \" \") for text in texts]\n",
    "   outputs = client.embeddings.create(input = texts, model=model)\n",
    "   return [outputs.data[i].embedding for i in range(len(texts))]\n",
    "\n",
    "texts=[\"hello\"]\n",
    "len(get_embeddings(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Coroutine, List\n",
    "\n",
    "\n",
    "class NewOpenAIEmbeddings(BaseModel, Embeddings):\n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        return get_embeddings(texts)\n",
    "    def aembed_documents(self, texts: List[str]) -> Coroutine[Any, Any, List[List[float]]]:\n",
    "        return get_embeddings(texts)\n",
    "    def aembed_query(self, text: str) -> Coroutine[Any, Any, List[float]]:\n",
    "        return get_embeddings([text])[0]\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return get_embeddings([text])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size =100, chunk_overlap = 50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "doc_splits = doc_splits[:50]\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NewOpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a retriever tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "tool = create_retriever_tool(\n",
    "    retriever, \n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Search and return information about Lilian Weng blog posts on LLM agents\"\n",
    ")\n",
    "\n",
    "tools = [tool]\n",
    "\n",
    "from langgraph.prebuilt import ToolExecutor\n",
    "\n",
    "tool_executor = ToolExecutor(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent State\n",
    "We will define the graph.\n",
    "\n",
    "A state object that it passes around to each node.\n",
    "Our state will be a list of `messages`.\n",
    "Each node in our graph will append to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated, Sequence, TypedDict\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Nodes and Edges\n",
    "We can lay out an agentic RAG graph like this:\n",
    "- The state is a set of messages\n",
    "- Each node will update (append to ) sate\n",
    "- Conditional edges decide which node to visit next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain import hub\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.tools.render import format_tool_to_openai_function\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import ToolInvocation\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_retrieve(state):\n",
    "    \"\"\"\n",
    "    Decides whether the agent should retrieve more information or end the process. \n",
    "    This function checks the last message in the state for a function call. If a function call is present, the process continues to retrieve information.\n",
    "    Otherwise, it ends the process\n",
    "    \"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    last_message: BaseMessage = messages[-1]\n",
    "    \n",
    "    if \"tool_calls\" not in last_message.additional_kwargs:\n",
    "        print(\"---DECISION: DO NOT RETRIEVE / DONE ---\")\n",
    "        return \"end\"\n",
    "    \n",
    "    else:\n",
    "        print(\"---DECISION: RETRIEVE ---\")\n",
    "        return \"continue\"\n",
    "        \n",
    "        \n",
    "def grade_documents(state: AgentState):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the quesiton.\n",
    "    \"\"\"\n",
    "    print(\"---CHECK RELEVANCE---\")\n",
    "    \n",
    "    class grade(BaseModel):\n",
    "        \"\"\" Binary score for relevance check.\"\"\"\n",
    "        binary_score:str = Field(description=\"Relevance score 'yes' or 'no'\" )\n",
    "    \n",
    "    model = ChatOpenAI(temperature=0, model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "    \n",
    "    grade_tool_oai = convert_to_openai_tool(grade)\n",
    "    \n",
    "    llm_with_tool = model.bind(\n",
    "        tools = [convert_to_openai_tool(grade_tool_oai)],\n",
    "        tool_choice={\"type\": \"function\", \"function\": {\"name\": \"grade\"}}\n",
    "    )\n",
    "    \n",
    "    parser_tool = PydanticToolsParser(tools=[grade])\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "                    Here is the retrieved document: \\n\\n {context} \\n\\n\n",
    "                    Here is the user question: {question} \\n\n",
    "                    If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "                    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\"\"\",\n",
    "        input_variables=[\"context\", \"question\"],\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm_with_tool | parser_tool \n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "    \n",
    "    score = chain.invoke(\n",
    "        {\"question\": question, \"context\": docs}\n",
    "    )\n",
    "    \n",
    "    llm_grade = score[0].binary_score \n",
    "    if llm_grade == \"yes\":\n",
    "        print(\"---DECISION: DOCS RELEVANT ---\")\n",
    "        return \"yes\"\n",
    "    else:\n",
    "        print(\"---DECISION: DOCS NOT RELVANT ---\")\n",
    "        print(score.binary_score)\n",
    "        return \"no\"\n",
    "    \n",
    "\n",
    "def agent(state: AgentState):\n",
    "    \"\"\"\n",
    "    Invoke the agent model to generate a response based on the current state. Given the question, it will decide to \n",
    "    retrieve using the retriever tool, or simply end.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"---CALL AGENT---\")\n",
    "    messages = state[\"messages\"]\n",
    "    model = ChatOpenAI(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "    functions = [format_tool_to_openai_function(t) for t in tools]\n",
    "    model = model.bind_functions(functions)\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def retrieve(state: AgentState):\n",
    "    \"\"\"\n",
    "    Uses tool to execute retrieval\n",
    "    \"\"\"\n",
    "    print(\"--EXECUTE RETRIEVAL\")\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    \n",
    "    action = ToolInvocation(\n",
    "        tool=last_message.additional_kwargs[\"tool_calls\"][0][\"function\"][\"name\"],\n",
    "        tool_input = json.loads(last_message.additional_kwargs[\"tool_calls\"][0][\"function\"][\"arguments\"])\n",
    "    )\n",
    "    response = tool_executor.invoke(action)\n",
    "    function_message = FunctionMessage(content=str(response), name=action.tool)\n",
    "    \n",
    "    return {\"messages\": [function_message]}\n",
    "\n",
    "\n",
    "def rewrite(state: AgentState): \n",
    "    \"\"\" \n",
    "    Transform the query to produce a better question.\n",
    "    \"\"\"\n",
    "    print(\"---TRANSFORM QUERY---\")\n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    question = messages[0].content\n",
    "    \n",
    "    msg = HumanMessage(\n",
    "        content=f\"\"\"\\n Look at the input and try to reason about the underlying semantic intent/meaning. \n",
    "        \\n Here is the initial question: \\n ---- \\n {question} \\n ----- \\n Formulate an imporoved question:\"\"\")\n",
    "    \n",
    "    model= ChatOpenAI(temperature=0, model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\"),\n",
    "    response = model.invoke(msg)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def generate(state: AgentState):\n",
    "    \"\"\" \n",
    "    Generate answer\n",
    "    \"\"\"\n",
    "    print(\"---GENERATE---\")\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    last_message:BaseMessage = messages[-1]\n",
    "    \n",
    "    \n",
    "    question = messages[0].content\n",
    "    docs = last_message.content\n",
    "    \n",
    "    prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "    \n",
    "    llm = ChatOpenAI(model_name=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    \n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    response = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph\n",
    "- Start with an agent, `call_model`\n",
    "- Agent make a decision to call a function\n",
    "- If so, ten `action` to call tool (retriever)\n",
    "- Then call agent with the tool output added to messages (`state`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"retrieve\", retrieve)\n",
    "workflow.add_node(\"rewrite\", rewrite)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", should_retrieve, {\n",
    "    \"continue\": \"retrieve\",\n",
    "    \"end\": END\n",
    "})\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    grade_documents,\n",
    "    {\n",
    "        \"yes\": \"generate\",\n",
    "        \"no\": \"rewrite\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "workflow.add_edge(\"generate\", END)\n",
    "workflow.add_edge(\"rewrite\", \"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CALL AGENT---\n",
      "'output from node agent'\n",
      "'----'\n",
      "{ 'messages': [ AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gcdgmqtfcmy7lgvi6wqjkgya', 'function': {'arguments': '{\"query\":\"types of agent memory in Lilian Weng\\'s blog\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}]})]}\n",
      "'\\n----\\n'\n",
      "---DECISION: RETRIEVE ---\n",
      "--EXECUTE RETRIEVAL\n",
      "'output from node retrieve'\n",
      "'----'\n",
      "{ 'messages': [ FunctionMessage(content='[Document(page_content=\\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\', metadata={\\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\"}), Document(page_content=\\'Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\', metadata={\\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\"}), Document(page_content=\\'PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\', metadata={\\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\"}), Document(page_content=\\'Planning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\', metadata={\\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\"})]', name='retrieve_blog_posts')]}\n",
      "'\\n----\\n'\n",
      "---CHECK RELEVANCE---\n",
      "---DECISION: DOCS RELEVANT ---\n",
      "---GENERATE---\n",
      "'output from node generate'\n",
      "'----'\n",
      "{ 'messages': [ ' Lilian Weng describes two types of agent memory in the '\n",
      "                'context of LLM-powered autonomous agent systems. These are:\\n'\n",
      "                '\\n'\n",
      "                '1. Subgoal and decomposition: This involves breaking down '\n",
      "                'large tasks into smaller, manageable subgoals for efficient '\n",
      "                'handling of complex tasks.\\n'\n",
      "                '2. Reflection and refinement: This is where the agent '\n",
      "                'reflects on past actions, learns from mistakes, and refines '\n",
      "                'them for future steps, with the aim of improving the quality '\n",
      "                'of final results.']}\n",
      "'\\n----\\n'\n",
      "'output from node __end__'\n",
      "'----'\n",
      "{ 'messages': [ HumanMessage(content='What does Lilian Weng say about the types of agent memory?'),\n",
      "                AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gcdgmqtfcmy7lgvi6wqjkgya', 'function': {'arguments': '{\"query\":\"types of agent memory in Lilian Weng\\'s blog\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}]}),\n",
      "                FunctionMessage(content='[Document(page_content=\\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview#\\', metadata={\\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\"}), Document(page_content=\\'Fig. 1. Overview of a LLM-powered autonomous agent system.\\\\nComponent One: Planning#\\\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\\\nTask Decomposition#\\', metadata={\\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\"}), Document(page_content=\\'PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\', metadata={\\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\"}), Document(page_content=\\'Planning\\\\n\\\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\\\n\\\\n\\\\nMemory\\', metadata={\\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\', \\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\"})]', name='retrieve_blog_posts'),\n",
      "                ' Lilian Weng describes two types of agent memory in the '\n",
      "                'context of LLM-powered autonomous agent systems. These are:\\n'\n",
      "                '\\n'\n",
      "                '1. Subgoal and decomposition: This involves breaking down '\n",
      "                'large tasks into smaller, manageable subgoals for efficient '\n",
      "                'handling of complex tasks.\\n'\n",
      "                '2. Reflection and refinement: This is where the agent '\n",
      "                'reflects on past actions, learns from mistakes, and refines '\n",
      "                'them for future steps, with the aim of improving the quality '\n",
      "                'of final results.']}\n",
      "'\\n----\\n'\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs ={\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            content=\"What does Lilian Weng say about the types of agent memory?\"\n",
    "            # content=\"Hello there\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint.pprint(f\"output from node {key}\")\n",
    "        pprint.pprint(\"----\")\n",
    "        pprint.pprint(value, indent=2, width=80, depth=None)\n",
    "    pprint.pprint(\"\\n----\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
