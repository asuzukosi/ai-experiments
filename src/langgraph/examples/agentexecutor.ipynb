{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Langgraph graphs using the Agent Executor\n",
    "In this notebook, we will go over building an agent executor using langgraph from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.tools.python.tool import PythonREPLTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "\n",
    "\n",
    "tools = [TavilySearchResults(max_results=1), PythonREPLTool()]\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "\n",
    "agent_runnable = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent_runnable, tools=tools)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the weather in sf?',\n",
       " 'output': ' [\\n  {\\n    \"name\": \"tavily_search_results_json\",\\n    \"arguments\": {\\n      \"query\": \"weather in sf\"\\n    }\\n  }\\n]'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is the weather in sf?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define the graph state\n",
    "We now define the graph state. The state for the tranditional langchain agent has a few attributes: \n",
    "\n",
    "- input : This is the input string representing the main ask from the user, passed in as input\n",
    "- chat_history: This is any previous conversation messages, also passed in as input\n",
    "- intermediate_steps: This is a list of actions and corresponding observations that the agent takes over time. This is updated each iteration of the agent\n",
    "- agent_outcome: This is the response from the agent, either an `AgentAction` or `AgentFinsh`. The AgentExecutor should finish when this is an agent finish, ohterwise it should call the requested tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict,Annotated, Union, Sequence, Tuple\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "from langchain_core.messages import BaseMessage\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    input: Annotated[str, operator.setitem]\n",
    "    chat_history: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    agent_outcome: Annotated[Union[AgentAction, AgentFinish, None], operator.setitem]\n",
    "    intermediate_steps: Annotated[Sequence[Tuple[AgentAction, str]], operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the nodes\n",
    "We now need to define a few different ndoes in our graph. In `langgraph`, a node cna be either a function or a runnable. There are two main nodes we need for thisl \n",
    "- The agent: responsible for deciding what (if any) action to take\n",
    "- A function to invoke tools: if the agent decides to taks an action, this node will then execute the action \n",
    "\n",
    "We will also need to define some edges. Some of these edges may be conditional. The reason they are conditional is that based on the output of the node, one of several paths may be taken. The path that is taken is not known until that node is run (the LLM decides).\n",
    "\n",
    "- Conditional Edge: after the agent is called, we should either: a. if the agent said to take an action, then the functio nto invoke tools shoudl be called b. If the agent said that it is finished, then it should finish\n",
    "- Normal Edge: after the tools are invokved, it should always go back to the agent to decide what to do next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolExecutor\n",
    "from langchain_core.agents import AgentFinish\n",
    "\n",
    "\n",
    "tool_executor = ToolExecutor(tools)\n",
    "\n",
    "\n",
    "def run_agent(state: AgentState):\n",
    "    agent_outcome = agent_runnable.invoke(state)\n",
    "    return {\"agent_outcome\": agent_outcome}\n",
    "\n",
    "def execute_tools(state: AgentState):\n",
    "    agent_action = state[\"agent_outcome\"]\n",
    "    output = tool_executor.invoke(agent_action)\n",
    "    return {\"intermediate_steps\": [(agent_action, str(output))]}\n",
    "\n",
    "def should_contine(state: AgentState):\n",
    "    if isinstance(state[\"agent_outcome\"], AgentFinish):\n",
    "        return \"end\"\n",
    "    \n",
    "    else:\n",
    "        return \"continue\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the graph\n",
    "We can now put everything together into a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"agent\", run_agent)\n",
    "workflow.add_node(\"action\", execute_tools)\n",
    "\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", should_contine, {\"continue\": \"action\", \"end\": END})\n",
    "workflow.add_edge(\"action\", \"agent\")\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"input\": \"what is the weather in sf?\", \"chat_history\": [], \"intermediate_steps\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output from node agent\n",
      "----\n",
      "{'agent_outcome': AgentFinish(return_values={'output': ''}, log='')}\n",
      "----\n",
      "output from node __end__\n",
      "----\n",
      "{'input': 'what is the weather in sf?', 'chat_history': [], 'agent_outcome': AgentFinish(return_values={'output': ''}, log=''), 'intermediate_steps': []}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"output from node {key}\")\n",
    "        print(\"----\")\n",
    "        print(value)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
