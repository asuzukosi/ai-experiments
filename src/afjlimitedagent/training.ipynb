{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing out th eopenai tools agent\n",
    "We would be testing the OpenAI tools agent provided by langchain to see if the agent will call the tool as opposed to simply returning the structured output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.agents.openai_tools.base import create_openai_tools_agent\n",
    "from langchain import hub\n",
    "from langchain.agents.agent import AgentExecutor\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [TavilySearchResults(max_results=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-tools-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the LLM that will drive the agent\n",
    "# Only certain models support this\n",
    "llm = ChatOpenAI(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", temperature=0)\n",
    "\n",
    "# Construct the OpenAI Tools agent\n",
    "agent = create_openai_tools_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m [\n",
      "  {\n",
      "    \"name\": \"tavily_search_results_json\",\n",
      "    \"arguments\": {\n",
      "      \"query\": \"LangChain\"\n",
      "    }\n",
      "  }\n",
      "]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke({\"input\": \"what is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = response[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'tavily_search_results_json', 'arguments': {'query': 'LangChain'}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "response = json.loads(response)[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily = TavilySearchResults(max_results=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://blog.paperspace.com/langchain/',\n",
       "  'content': \"Blog\\nSample projects, release notes, and more\\nDocs\\nView the docs hub and tutorials\\nCommunity\\nA forum to share ideas and learn new tools\\nML\\xa0Showcase\\nSample projects you can clone into your account\\nProfessional Services\\nGet expert advice on your ML projects\\nTalk to an Expert\\nFind the right solution for your organization\\nLangChain: A Beginner's Guide to Harness the Power of Language Models\\nIn this tutorial, we show how to get started with LangChain: a useful package for streamlining your Large Language Model pipelines.\\n Refrences\\nAdd speed and simplicity to your Machine Learning workflow today\\nFor further reading on LLMs\\nSpread the word\\nGPU Computing for Accelerating Drug Discovery Processes\\nKeep reading\\nHow to use H100 Single and Multi-GPU machines with Paperspace\\nMemGPT with Real-life Example: LangChain demo\\nBring this project to life\\nThis article guides you through the process of constructing a text summarizer by utilizing the Hugging Face API and leveraging the Bart model for summarization.\\n Bridging the Gap Between AI and OS\\nInnovating Speech Synthesis:\\nHierarchical Variational Approach in HierSpeech++\\nSubscribe to our newsletter\\nStay updated with Paperspace Blog by signing up for our newsletter.\\n Additionally, the collaboration between HuggingFace and LangChain sets the stage for groundbreaking advancements in Natural Language Processing (NLP), offering the potential for more advanced language models and enhanced language comprehension across a multitude of applications and industries.\\n\"}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.run(tool_input=response[\"arguments\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
