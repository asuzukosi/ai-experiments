{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this example we would be building a simple vector store with llama index\n",
    "We've covered various ideas in llama index, now we would be exploring combining thos basic ideas to implement a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.indices.vector_store import VectorStoreIndex\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "from llama_index.storage import StorageContext\n",
    "from llama_index.indices.loading import load_index_from_storage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-10 22:59:50--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 75042 (73K) [text/plain]\n",
      "Saving to: ‘data/paul_graham/paul_graham_essay.txt’\n",
      "\n",
      "data/paul_graham/pa 100%[===================>]  73.28K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2024-02-10 22:59:51 (1.41 MB/s) - ‘data/paul_graham/paul_graham_essay.txt’ saved [75042/75042]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/paul_graham/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.file.base import SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex.from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'c4c7eb35-392d-4546-99a0-78481984f168': RefDocInfo(node_ids=['3037ad99-71c6-4f2f-b9dc-2b766d990cec', '95d7d3ab-7f10-46e5-814a-624e45ddb42e', '5563f361-7183-4137-a9a3-3aca7b751374', 'a7ce764d-ebb4-4898-aa54-e088cbf966bf', '802ded21-4118-4b30-b2b6-d45621edc503', '9239476c-c099-403f-8afb-43db77ce8dbb', '28f208d1-54c0-47ff-b3d2-bdf108fb1ab1', '2381c633-61c9-45e7-ad23-fb2bc67b0c0c', 'dc95d3b7-ebf3-4239-aad8-bbf51e0243e1', '86328329-23b6-4873-9212-5d99a7b787b7', '7a35fe7c-66f1-4841-b0dc-5d2becdb6318', 'b7d4c21a-cf49-454a-bab4-d84a87564a23', '09389635-1134-4233-8fca-c924f551a712', 'ad1fc8c0-cfeb-4d5a-943a-7d52e901c7f1', 'b6ebd551-99c0-4913-8fc9-620695784809', '19ce608e-7c7e-416b-8d83-2f635dd78acf', '3fd18065-877f-42c2-8e28-3b26ba901005', '282cd029-0409-4720-9d60-b8f4746c6bf5', '1b4be1e5-e52d-4f79-9f27-87380881fcf3', '240d812e-9e89-4779-af8d-a05ae4dcca2e', '38851cc5-11ee-4f05-b662-c752d8d6d6af', 'cac44424-310a-4621-ae86-80c9f212a71b'], metadata={'file_path': 'data/paul_graham/paul_graham_essay.txt', 'file_name': 'paul_graham_essay.txt', 'file_type': 'text/plain', 'file_size': 75042, 'creation_date': '2024-02-10', 'last_modified_date': '2024-02-10', 'last_accessed_date': '2024-02-10'})}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.ref_doc_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.set_index_id(\"vector_index\")\n",
    "index.storage_context.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stored index\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"storage\")\n",
    "index = load_index_from_storage(storage_context=storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(response_mode=\"tree_summarize\")\n",
    "response = query_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The author grew up to the point where he was able to write software, start a company, and sell it to Yahoo. After that, he became wealthy and decided to pursue his passion for painting. He faced challenges adjusting to his new life in California and eventually returned to New York to continue painting and resume his old patterns, now with the added luxury of taxis and charming restaurants. He experimented with new techniques for painting and looked for an apartment to buy in his preferred neighborhood.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kosisochukwuasuzu/Developer/ai-startups/test-demos/pdfchat/venv/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query mode: svm\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The author, Paul Graham, has the skill of leading and managing a startup incubator, Y Combinator, and writing essays. He also has the ability to identify and recruit talented individuals to take over and lead the organization. Additionally, he demonstrates strong problem-solving abilities and a dedication to working hard to ensure the success of the startups under his care.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kosisochukwuasuzu/Developer/ai-startups/test-demos/pdfchat/venv/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query mode: linear_regression\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The author, Paul Graham, is an expert in running start-up incubators, such as Y Combinator. He is also skilled in programming, having written software in various languages including Arc and Lisp. Additionally, he has strong leadership abilities, as evidenced by his role in leading and eventually passing the leadership of Y Combinator to Sam Altman.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kosisochukwuasuzu/Developer/ai-startups/test-demos/pdfchat/venv/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query mode: logistic_regression\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "<b>The author, Paul Graham, has the skill of leading and managing a startup incubator, Y Combinator, and writing essays. He also has the ability to identify and recruit talented individuals to take over and lead the organization. Additionally, he demonstrates strong problem-solving abilities and a dedication to working hard to ensure the success of the startups under his care.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query_modes = [\n",
    "    \"svm\",\n",
    "    \"linear_regression\",\n",
    "    \"logistic_regression\",\n",
    "]\n",
    "for query_mode in query_modes:\n",
    "    # set Logging to DEBUG for more detailed outputs\n",
    "    query_engine = index.as_query_engine(vector_store_query_mode=query_mode)\n",
    "    response = query_engine.query(\"What skill does the author have?\")\n",
    "    print(f\"Query mode: {query_mode}\")\n",
    "    display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18] The worst thing about leaving YC was not working with Jessica anymore. We'd been working on YC almost the whole time we'd known each other, and we'd neither tried nor wanted to separate it from our personal lives, so leaving was like pulling up a deeply rooted tree.\n",
      "\n",
      "[19] One way to get more precise about the concept of invented vs discovered is to talk about space aliens. Any sufficiently advanced alien civilization would certainly know about the Pythagorean theorem, for example. I believe, though with less certainty, that they would also know about the Lisp in McCarthy's 1960 paper.\n",
      "\n",
      "But if so there's no reason to suppose that this is the limit of the language that might be known to them. Presumably aliens need numbers and errors and I/O too. So it seems likely there exists at least one path out of McCarthy's Lisp along which discoveredness is preserved.\n",
      "\n",
      "\n",
      "\n",
      "Thanks to Trevor Blackwell, John Collison, Patrick Collison, Daniel Gackle, Ralph Hazell, Jessica Livingston, Robert Morris, and Harj Taggar for reading drafts of this.\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import QueryBundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_bundle = QueryBundle(\n",
    "    query_str=\"What did the author do growing up?\",\n",
    "    custom_embedding_strs=[\"The author grew up painting.\"],\n",
    ")\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(query_bundle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The author grew up hearing about the World Wide Web and became interested in '\n",
      " 'its potential. He decided to start a company to put art galleries online, '\n",
      " 'but this idea was not successful. He then focused on creating software for '\n",
      " 'building online stores, which led to the development of web applications. '\n",
      " 'The author also had an idea for a web app to help create other web apps and '\n",
      " 'started a new company called Aspra to pursue this idea. However, he '\n",
      " 'eventually decided to build a subset of this project as an open source '\n",
      " \"project instead. The author's experiences with starting companies and \"\n",
      " 'developing software influenced his later work with Y Combinator.')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(\n",
    "    vector_store_query_mode=\"mmr\", vector_store_kwargs={\"mmr_threshold\": 0.2}\n",
    ")\n",
    "response = query_engine.query(\"What did the author do growing up?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The author does not provide any information about what he did growing up in '\n",
      " 'the context information provided.')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: b6ebd551-99c0-4913-8fc9-620695784809): As Jessica and I were walking home from dinner on March 11, at the corner of Garden and Walker st...\n",
      "\n",
      "> Source (Doc id: cac44424-310a-4621-ae86-80c9f212a71b): [18] The worst thing about leaving YC was not working with Jessica anymore. We'd been working on ...\n"
     ]
    }
   ],
   "source": [
    "print(response.get_formatted_sources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.schema import Document\n",
    "\n",
    "doc = Document(text=\"target\", metadata={\"tag\": \"target\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "index.insert(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.types import ExactMatchFilter, MetadataFilters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = MetadataFilters(\n",
    "    filters= [ExactMatchFilter(key=\"tag\", value=\"target\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "retreiver = VectorIndexRetriever(\n",
    "    index=index,\n",
    "    filters=filters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retreiver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = query_engine.query(\"what was the authors hobby\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I cannot provide an answer based on the given context as it does not provide '\n",
      " \"sufficient information about the author's hobby.\")\n"
     ]
    }
   ],
   "source": [
    "pprint(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.source_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'> Source (Doc id: f343bbd3-fb16-428d-8cac-eae83a4922e0): target'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.get_formatted_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_nodes = response.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "{'tag': 'target'}\n"
     ]
    }
   ],
   "source": [
    "print(source_nodes[0].text)\n",
    "print(source_nodes[0].metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
