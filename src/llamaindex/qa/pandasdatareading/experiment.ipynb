{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Pandas data \n",
    "We can use our qa system to ask questions about our data using llama index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.readers.file.base import SimpleDirectoryReader\n",
    "from llama_index.query_engine.pandas import PandasQueryEngine\n",
    "from llama_index.service_context import ServiceContext\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on some sample data\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"city\": [\"Toronto\", \"Tokyo\", \"Berlin\"],\n",
    "        \"population\": [2930000, 13960000, 3645000],\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\")\n",
    "service_context = ServiceContext.from_defaults(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = PandasQueryEngine(df=df, service_context=service_context, synthesize_response=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Pandas Instructions:\n",
      "```\n",
      "df['city'][df['population'].idxmax()]\n",
      "```\n",
      "> Pandas Output: Tokyo\n",
      "'The city with the highest population is Tokyo.'\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"what is name of the city with the highest population?\")\n",
    "pprint(response.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That was fun now lets analyze the Titanic dataset\n",
    "We would be downloading the titanic dataset and using the PandasQueryEngine provided by llama index to extract data from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-02-11 23:19:04--  https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/csv/titanic_train.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 57726 (56K) [text/plain]\n",
      "Saving to: ‘data/titanic_train.csv’\n",
      "\n",
      "data/titanic_train. 100%[===================>]  56.37K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2024-02-11 23:19:05 (1.84 MB/s) - ‘data/titanic_train.csv’ saved [57726/57726]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://raw.githubusercontent.com/jerryjliu/llama_index/main/docs/examples/data/csv/titanic_train.csv' -O 'data/titanic_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/titanic_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = PandasQueryEngine(df=df, service_context=service_context, synthesize_response=True, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Pandas Instructions:\n",
      "```\n",
      "df[df['age'] == df['age'].min()][['survived', 'pclass', 'age', 'name', 'sex', 'embarked']]\n",
      "```\n",
      "> Pandas Output:      survived  pclass   age                             name   sex embarked\n",
      "803         1       3  0.42  Thomas, Master. Assad Alexander  male        C\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"What is the age of the youngest person on the dataset and their other information?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The youngest person in the dataset is 0.42 years old at the time of the '\n",
      " 'survey. This individual is listed as \"Thomas, Master. Assad Alexander,\" and '\n",
      " 'is identified as male. They were traveling in third class, and embarked from '\n",
      " 'the port labeled \"C.\" Based on the \\'survived\\' column, it is unclear '\n",
      " 'whether they survived or not, as the value is listed as 1, which could '\n",
      " 'indicate a survived passenger, but could also be an ID number or some other '\n",
      " 'unrelated value. More information about the context of the dataset would be '\n",
      " 'needed to accurately interpret this value.')\n"
     ]
    }
   ],
   "source": [
    "pprint(response.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = query_engine.get_prompts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pandas_prompt', 'response_synthesis_prompt'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You are working with a pandas dataframe in Python.\\n'\n",
      " 'The name of the dataframe is `df`.\\n'\n",
      " 'This is the result of `print(df.head())`:\\n'\n",
      " '{df_str}\\n'\n",
      " '\\n'\n",
      " 'Follow these instructions:\\n'\n",
      " '{instruction_str}\\n'\n",
      " 'Query: {query_str}\\n'\n",
      " '\\n'\n",
      " 'Expression:')\n"
     ]
    }
   ],
   "source": [
    "pprint(prompts[\"pandas_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Given an input question, synthesize a response from the query results.\\n'\n",
      " 'Query: {query_str}\\n'\n",
      " '\\n'\n",
      " 'Pandas Instructions (optional):\\n'\n",
      " '{pandas_instructions}\\n'\n",
      " '\\n'\n",
      " 'Pandas Output: {pandas_output}\\n'\n",
      " '\\n'\n",
      " 'Response: ')\n"
     ]
    }
   ],
   "source": [
    "pprint(prompts[\"response_synthesis_prompt\"].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
