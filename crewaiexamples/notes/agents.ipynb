{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel # the base model comes from pydantic which does not come with any programmable logic\n",
    "from pydantic import PrivateAttr, ConfigDict, UUID4, Field, field_validator, InstanceOf, model_validator\n",
    "import uuid\n",
    "import os\n",
    "from typing import Any, List, Optional,Tuple\n",
    "from logging import Logger \n",
    "from crewai.utilities import RPMController # RPMController limits the amount of continous request that can be made to an LLM \n",
    "from crewai.agents import CrewAgentExecutor, ToolsHandler, CacheHandler, CrewAgentParser\n",
    "from langchain.memory import ConversationSummaryMemory # Conversation summary memory summarizes all previous messages when a particular previous message token limit is reached. \n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from crewai.utilities import Prompts, I18N\n",
    "from pydantic_core import PydanticCustomError\n",
    "from langchain.tools.render import render_text_description\n",
    "from langchain_core.agents import AgentAction\n",
    "from crewai_tools import BaseTool as CrewAITool\n",
    "from langchain.agents.tools import tool as LangChainTool\n",
    "from langchain.agents.agent import RunnableAgent\n",
    "\n",
    "\n",
    "\n",
    "class Agent(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents an agent in a system.\n",
    "\n",
    "    Each agent has a role, a goal, a backstory, and an optional language model (llm).\n",
    "    The agent can also have memory, can operate in verbose mode, and can delegate tasks to other agents.\n",
    "\n",
    "    Attributes:\n",
    "            agent_executor: An instance of the CrewAgentExecutor class.\n",
    "            role: The role of the agent.\n",
    "            goal: The objective of the agent.\n",
    "            backstory: The backstory of the agent.\n",
    "            \n",
    "            \n",
    "            # whats the difference between llm and function_calling_llm\n",
    "            llm: The language model that will run the agent.\n",
    "            function_calling_llm: The language model that will the tool calling for this agent, it overrides the crew function_calling_llm.\n",
    "            \n",
    "            \n",
    "            max_iter: Maximum number of iterations for an agent to execute a task.\n",
    "            memory: Whether the agent should have memory or not.\n",
    "            max_rpm: Maximum number of requests per minute for the agent execution to be respected.\n",
    "            verbose: Whether the agent execution should be in verbose mode.\n",
    "            allow_delegation: Whether the agent is allowed to delegate tasks to other agents.\n",
    "            tools: Tools at agents disposal\n",
    "            step_callback: Callback to be executed after each step of the agent execution.\n",
    "    \"\"\"\n",
    "\n",
    "    __hash__ = object.__hash__  # type: ignore\n",
    "    _logger: Logger = PrivateAttr()\n",
    "    _rpm_controller: RPMController = PrivateAttr(default=None)\n",
    "    _request_within_rpm_limit: Any = PrivateAttr(default=None)\n",
    "\n",
    "    model_config = ConfigDict(arbitrary_types_allowed=True)\n",
    "    # each agent has an automatically generated id when it is created, this is useful for tracking the agentt\n",
    "    id: UUID4 = Field(\n",
    "        default_factory=uuid.uuid4,\n",
    "        frozen=True,\n",
    "        description=\"Unique identifier for the object, not set by user.\",\n",
    "    )\n",
    "    role: str = Field(description=\"Role of the agent\")\n",
    "    goal: str = Field(description=\"Objective of the agent\")\n",
    "    backstory: str = Field(description=\"Backstory of the agent\")\n",
    "    max_rpm: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Maximum number of requests per minute for the agent execution to be respected.\",\n",
    "    )\n",
    "    memory: bool = Field(\n",
    "        default=True, description=\"Whether the agent should have memory or not\"\n",
    "    )\n",
    "    verbose: bool = Field(\n",
    "        default=False, description=\"Verbose mode for the Agent Execution\"\n",
    "    )\n",
    "    allow_delegation: bool = Field(\n",
    "        default=True, description=\"Allow delegation of tasks to agents\"\n",
    "    )\n",
    "    tools: Optional[List[Any]] = Field(\n",
    "        default_factory=list, description=\"Tools at agents disposal\"\n",
    "    )\n",
    "    max_iter: Optional[int] = Field(\n",
    "        default=15, description=\"Maximum iterations for an agent to execute a task\"\n",
    "    )\n",
    "    agent_executor: InstanceOf[CrewAgentExecutor] = Field(\n",
    "        default=None, description=\"An instance of the CrewAgentExecutor class.\"\n",
    "    )\n",
    "    tools_handler: InstanceOf[ToolsHandler] = Field(\n",
    "        default=None, description=\"An instance of the ToolsHandler class.\"\n",
    "    )\n",
    "    cache_handler: InstanceOf[CacheHandler] = Field(\n",
    "        default=CacheHandler(), description=\"An instance of the CacheHandler class.\"\n",
    "    )\n",
    "    step_callback: Optional[Any] = Field(\n",
    "        default=None,\n",
    "        description=\"Callback to be executed after each step of the agent execution.\",\n",
    "    )\n",
    "    i18n: I18N = Field(default=I18N(), description=\"Internationalization settings.\")\n",
    "    llm: Any = Field(\n",
    "        default_factory=lambda: ChatOpenAI(\n",
    "            model=os.environ.get(\"OPENAI_MODEL_NAME\", \"gpt-4\")\n",
    "        ),\n",
    "        description=\"Language model that will run the agent.\",\n",
    "    )\n",
    "    function_calling_llm: Optional[Any] = Field(\n",
    "        description=\"Language model that will run the agent.\", default=None\n",
    "    )\n",
    "\n",
    "    @field_validator(\"id\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _deny_user_set_id(cls, v: Optional[UUID4]) -> None:\n",
    "        if v:\n",
    "            raise PydanticCustomError(\n",
    "                \"may_not_set_field\", \"This field is not to be set by the user.\", {}\n",
    "            )\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def set_private_attrs(self):\n",
    "        \"\"\"Set private attributes.\"\"\"\n",
    "        self._logger = Logger(self.verbose)\n",
    "        if self.max_rpm and not self._rpm_controller:\n",
    "            self._rpm_controller = RPMController(\n",
    "                max_rpm=self.max_rpm, logger=self._logger\n",
    "            )\n",
    "        return self\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def check_agent_executor(self) -> \"Agent\":\n",
    "        \"\"\"Check if the agent executor is set.\"\"\"\n",
    "        if not self.agent_executor:\n",
    "            self.set_cache_handler(self.cache_handler)\n",
    "        return self\n",
    "\n",
    "    def execute_task(\n",
    "        self,\n",
    "        task: Any,\n",
    "        context: Optional[str] = None,\n",
    "        tools: Optional[List[Any]] = None,\n",
    "    ) -> str:\n",
    "        \"\"\"Execute a task with the agent.\n",
    "\n",
    "        Args:\n",
    "            task: Task to execute.\n",
    "            context: Context to execute the task in.\n",
    "            tools: Tools to use for the task.\n",
    "\n",
    "        Returns:\n",
    "            Output of the agent\n",
    "        \"\"\"\n",
    "        task_prompt = task.prompt()\n",
    "\n",
    "        if context:\n",
    "            task_prompt = self.i18n.slice(\"task_with_context\").format(\n",
    "                task=task_prompt, context=context\n",
    "            )\n",
    "\n",
    "        tools = self._parse_tools(tools or self.tools)\n",
    "        self.create_agent_executor(tools=tools)\n",
    "        self.agent_executor.tools = tools\n",
    "        self.agent_executor.task = task\n",
    "        self.agent_executor.tools_description = render_text_description(tools)\n",
    "        self.agent_executor.tools_names = self.__tools_names(tools)\n",
    "\n",
    "        result = self.agent_executor.invoke(\n",
    "            {\n",
    "                \"input\": task_prompt,\n",
    "                \"tool_names\": self.agent_executor.tools_names,\n",
    "                \"tools\": self.agent_executor.tools_description,\n",
    "            }\n",
    "        )[\"output\"]\n",
    "\n",
    "        if self.max_rpm:\n",
    "            self._rpm_controller.stop_rpm_counter()\n",
    "\n",
    "        return result\n",
    "\n",
    "    def set_cache_handler(self, cache_handler: CacheHandler) -> None:\n",
    "        \"\"\"Set the cache handler for the agent.\n",
    "\n",
    "        Args:\n",
    "            cache_handler: An instance of the CacheHandler class.\n",
    "        \"\"\"\n",
    "        self.cache_handler = cache_handler\n",
    "        self.tools_handler = ToolsHandler(cache=self.cache_handler)\n",
    "        self.create_agent_executor()\n",
    "\n",
    "    def set_rpm_controller(self, rpm_controller: RPMController) -> None:\n",
    "        \"\"\"Set the rpm controller for the agent.\n",
    "\n",
    "        Args:\n",
    "            rpm_controller: An instance of the RPMController class.\n",
    "        \"\"\"\n",
    "        if not self._rpm_controller:\n",
    "            self._rpm_controller = rpm_controller\n",
    "            self.create_agent_executor()\n",
    "\n",
    "    def create_agent_executor(self, tools=None) -> None:\n",
    "        \"\"\"Create an agent executor for the agent.\n",
    "\n",
    "        Returns:\n",
    "            An instance of the CrewAgentExecutor class.\n",
    "        \"\"\"\n",
    "        tools = tools or self.tools\n",
    "\n",
    "        agent_args = {\n",
    "            \"input\": lambda x: x[\"input\"],\n",
    "            \"tools\": lambda x: x[\"tools\"],\n",
    "            \"tool_names\": lambda x: x[\"tool_names\"],\n",
    "            \"agent_scratchpad\": lambda x: self.format_log_to_str(\n",
    "                x[\"intermediate_steps\"]\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        executor_args = {\n",
    "            \"llm\": self.llm,\n",
    "            \"i18n\": self.i18n,\n",
    "            \"tools\": self._parse_tools(tools),\n",
    "            \"verbose\": self.verbose,\n",
    "            \"handle_parsing_errors\": True,\n",
    "            \"max_iterations\": self.max_iter,\n",
    "            \"step_callback\": self.step_callback,\n",
    "            \"tools_handler\": self.tools_handler,\n",
    "            \"function_calling_llm\": self.function_calling_llm,\n",
    "        }\n",
    "\n",
    "        if self._rpm_controller:\n",
    "            executor_args[\n",
    "                \"request_within_rpm_limit\"\n",
    "            ] = self._rpm_controller.check_or_wait\n",
    "\n",
    "        if self.memory:\n",
    "            summary_memory = ConversationSummaryMemory(\n",
    "                llm=self.llm, input_key=\"input\", memory_key=\"chat_history\"\n",
    "            )\n",
    "            executor_args[\"memory\"] = summary_memory\n",
    "            agent_args[\"chat_history\"] = lambda x: x[\"chat_history\"]\n",
    "            prompt = Prompts(i18n=self.i18n, tools=tools).task_execution_with_memory()\n",
    "        else:\n",
    "            prompt = Prompts(i18n=self.i18n, tools=tools).task_execution()\n",
    "\n",
    "        execution_prompt = prompt.partial(\n",
    "            goal=self.goal,\n",
    "            role=self.role,\n",
    "            backstory=self.backstory,\n",
    "        )\n",
    "\n",
    "        bind = self.llm.bind(stop=[self.i18n.slice(\"observation\")])\n",
    "        inner_agent = agent_args | execution_prompt | bind | CrewAgentParser()\n",
    "        self.agent_executor = CrewAgentExecutor(\n",
    "            agent=RunnableAgent(runnable=inner_agent), **executor_args\n",
    "        )\n",
    "\n",
    "    def _parse_tools(self, tools: List[Any]) -> List[LangChainTool]:\n",
    "        \"\"\"Parse tools to be used for the task.\"\"\"\n",
    "        tools_list = []\n",
    "        for tool in tools:\n",
    "            if isinstance(tool, CrewAITool):\n",
    "                tools_list.append(tool.to_langchain())\n",
    "            else:\n",
    "                tools_list.append(tool)\n",
    "        return tools_list\n",
    "\n",
    "    def format_log_to_str(\n",
    "        self,\n",
    "        intermediate_steps: List[Tuple[AgentAction, str]],\n",
    "        observation_prefix: str = \"Result: \",\n",
    "        llm_prefix: str = \"\",\n",
    "    ) -> str:\n",
    "        \"\"\"Construct the scratchpad that lets the agent continue its thought process.\"\"\"\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\n{observation_prefix}{observation}\\n{llm_prefix}\"\n",
    "        return thoughts\n",
    "\n",
    "    @staticmethod\n",
    "    def __tools_names(tools) -> str:\n",
    "        return \", \".join([t.name for t in tools])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
